# main_orchestrator.py
import asyncio
import json
from typing import List, Optional, Dict, Any
import os
from datetime import datetime, timezone


from config import BASE_OUTPUT_FOLDER # BASE_OUTPUT_FOLDER can remain if it's a fixed path in the container

from data_models import (
    Layer2Input, PostHistoryEntry, Requirements,
    PlatformAgentInput, PlatformAgentOutput,
    FinalGeneratedPost, SavedMediaAsset,
    TranslatorAgentInput
)
from llm_services import run_layer_2_decision_maker, run_platform_adaptation_agent, run_translator_agent
from media_generation import generate_visual_asset_for_platform
from file_utils import get_filename_base, ensure_platform_folder_exists, save_text_content
from cloud_storage_service import cloud_storage, upload_generated_post_files
from image_control_service import ImageControlProcessor
from api_models import ContentGeneratorData


# This function will now take all dynamic parameters
async def generate_social_media_posts_pipeline(
    subject: str,
    company_name: str,
    company_mission: str,
    company_sentiment: str,
    language: str,
    platforms_post_types_map: List[Dict[str, str]], # This is now a parameter
    tone: str, # Assuming TONE was also a global, make it a param
    requirements: Optional[Requirements] = None,
    posts_history: Optional[List[PostHistoryEntry]] = None,
    upload_to_cloud: bool = True,
) -> Dict[str, any]:
    """
    Generate social media posts, translate if necessary, and optionally upload to cloud storage.
    """
    print("üöÄ Starting Social Media Post Generation Pipeline üöÄ")

    # --- Derive target platforms from the map ---
    platform_configs: Dict[str, str] = {}
    for entry in platforms_post_types_map:
        if isinstance(entry, dict) and len(entry) == 1:
            platform_name, post_type = list(entry.items())[0]
            platform_configs[platform_name] = post_type
        else:
            print(f"‚ö†Ô∏è Warning: Invalid entry in platforms_post_types_map: {entry}. Skipping.")
            continue

    if not platform_configs:
        error_msg = "No valid platforms configured in platforms_post_types_map."
        print(f"üö´ Error: {error_msg} Aborting.")
        return {
            "error": error_msg,
            "pipeline_id": f"{get_filename_base(subject)}_error_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            "subject": subject,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "posts": [],
            "cloud_uploads": []
        }

    # --- Generate Filename Base ---
    filename_base = get_filename_base(subject)
    print(f"üé¨ Using filename base: {filename_base}")

    target_platforms_from_map = list(platform_configs.keys())
    print(f"üó∫Ô∏è Targeting platforms based on PLATFORMS_POST_TYPES_MAP: {', '.join(target_platforms_from_map)}")

    # Determine a general post type hint for Layer 2
    layer2_platform_post_type_hint = "General content"  # Default
    if platform_configs:
        unique_post_types = sorted(list(set(p_type for p_type in platform_configs.values() if p_type)))
        if unique_post_types:
            layer2_platform_post_type_hint = f"Content adaptable for {', '.join(unique_post_types)} posts"
        else:
            layer2_platform_post_type_hint = "General content for various platforms"

    # --- Layer 2: Core Text Generation ---
    layer2_input_data = Layer2Input(
        company_name=company_name,
        company_mission=company_mission,
        company_sentiment=company_sentiment,
        subject=subject,
        platforms_to_target=target_platforms_from_map,
        requirements=requirements,
        posts_history=posts_history,
        language=language,  # L2 gets target lang for context, but generates English
        tone=tone,
        platform_post_type=layer2_platform_post_type_hint  # Added this field
    )
    layer2_result = await run_layer_2_decision_maker(layer2_input_data)
    core_post_text = layer2_result["core_post_text"]
    print(f"üìù Core post text generated by Layer 2: '{core_post_text[:100]}...'")

    # --- Layer 3: Platform Adaptation ---
    platform_adaptation_tasks = []
    for platform_name, platform_post_type_from_map in platform_configs.items():
        print(f"‚öôÔ∏è Preparing adaptation for {platform_name} with post type: {platform_post_type_from_map}")
        platform_agent_input = PlatformAgentInput(
            company_name=company_name,
            company_mission=company_mission,
            company_sentiment=company_sentiment,
            language=language,  # Pass target language for context
            tone=tone,
            subject=subject,
            platform_post_type=platform_post_type_from_map,
            core_post_text_suggestion=core_post_text,
            target_platform=platform_name
        )
        platform_adaptation_tasks.append(
            (platform_name, platform_post_type_from_map, run_platform_adaptation_agent(platform_agent_input))
        )

    platform_agent_results_gathered = await asyncio.gather(*(task for _, _, task in platform_adaptation_tasks))

    platform_outputs_map: Dict[str, PlatformAgentOutput] = {}
    platform_post_types_used: Dict[str, str] = {}

    # Iterate through gathered results and perform translation if needed
    for i, platform_result_from_gather in enumerate(platform_agent_results_gathered):
        platform_name = platform_adaptation_tasks[i][0]
        platform_post_type_config_for_platform = platform_adaptation_tasks[i][1]

        # Make a mutable copy if needed, or ensure PlatformAgentOutput is a dict
        current_platform_output: PlatformAgentOutput = platform_result_from_gather

        # --- Translation Step ---
        if language.lower() != "english" and language.lower() != "en":  # More robust check
            original_english_text = current_platform_output["platform_specific_text"]
            print(f"üåç Translating content for {platform_name} from English to {language}...")
            translator_input = TranslatorAgentInput(
                text_to_translate=original_english_text,
                target_language=language,
                company_name=company_name,
                company_mission=company_mission,
                original_subject=subject
            )
            try:
                translation_output = await run_translator_agent(translator_input)
                current_platform_output["platform_specific_text"] = translation_output["translated_text"]
                print(f"üåç Translation successful for {platform_name}.")
            except Exception as e:
                print(
                    f"üö® Error translating content for {platform_name} to {language}: {e}. Using original English text.")
                # current_platform_output["platform_specific_text"] remains original_english_text

        platform_outputs_map[platform_name] = current_platform_output
        platform_post_types_used[platform_name] = platform_post_type_config_for_platform

    # --- Media Generation (if applicable, per platform) ---
    final_posts_results: List[FinalGeneratedPost] = []
    media_generation_coroutines = []
    platforms_needing_media_info: List[tuple[str, str, str]] = []

    for platform_name, platform_output_data in platform_outputs_map.items():  # Changed variable name
        current_platform_post_type_from_config = platform_post_types_used[platform_name]

        if current_platform_post_type_from_config in ["Image", "Video"]:
            media_prompt = platform_output_data.get("platform_media_generation_prompt")
            if media_prompt:
                platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
                media_type_to_generate = "image" if current_platform_post_type_from_config == "Image" else "video"

                print(
                    f"üñºÔ∏è Scheduling {media_type_to_generate} generation for {platform_name} (Prompt: '{media_prompt[:50]}...')")
                media_generation_coroutines.append(
                    generate_visual_asset_for_platform(
                        image_prompt=media_prompt,
                        output_directory=platform_dir,
                        filename_base=filename_base,
                        media_type=media_type_to_generate
                    )
                )
                platforms_needing_media_info.append((platform_name, media_prompt, media_type_to_generate))
            else:
                print(
                    f"‚ÑπÔ∏è Info: Platform agent for {platform_name} (type: {current_platform_post_type_from_config}) did not provide a media prompt.")
        else:
            print(
                f"‚ÑπÔ∏è Info: Platform {platform_name} is Text-only (type: {current_platform_post_type_from_config}). No media generation needed.")

    generated_media_paths: List[Optional[str]] = []
    if media_generation_coroutines:
        print(f"\n‚è≥ Starting {len(media_generation_coroutines)} media generation tasks...")
        try:
            results_or_exceptions = await asyncio.gather(*media_generation_coroutines, return_exceptions=True)
            for i, res_or_exc in enumerate(results_or_exceptions):
                platform_name_for_media, _, _ = platforms_needing_media_info[i]
                if isinstance(res_or_exc, Exception):
                    print(f"üö® Error generating media for {platform_name_for_media}: {res_or_exc}")
                    generated_media_paths.append(None)
                else:
                    generated_media_paths.append(res_or_exc)
        except Exception as e:
            print(f"üö® Major error during media generation gathering: {e}")
            generated_media_paths = [None] * len(platforms_needing_media_info)

    # --- Cloud Upload Tasks (Prepare) ---
    cloud_upload_tasks = []
    cloud_upload_results_list: List[Dict[str, Any]] = []

    # --- Assemble Final Posts and Prepare Cloud Uploads ---
    media_path_idx = 0
    for platform_name in target_platforms_from_map:
        platform_output_data = platform_outputs_map.get(platform_name)  # Changed variable name
        if not platform_output_data:
            print(f"‚ö†Ô∏è Warning: No platform output for {platform_name} during final assembly. Skipping.")
            continue

        platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
        # Text content is now potentially translated
        text_content = platform_output_data["platform_specific_text"]
        text_file_path = save_text_content(platform_dir, filename_base, text_content)

        current_media_asset: Optional[SavedMediaAsset] = None
        media_prompt_used_for_this_platform: Optional[str] = None
        media_file_path: Optional[str] = None
        # actual_media_type_generated: Optional[str] = None # Not used later, can remove if not needed for debugging

        media_info_for_platform = next((info for info in platforms_needing_media_info if info[0] == platform_name),
                                       None)

        if media_info_for_platform:
            original_prompt_for_platform = media_info_for_platform[1]
            requested_media_type = media_info_for_platform[2]

            if media_path_idx < len(generated_media_paths):
                path_or_none = generated_media_paths[media_path_idx]
                if path_or_none:
                    media_file_path = path_or_none
                    current_media_asset = SavedMediaAsset(
                        type=requested_media_type,
                        file_path=media_file_path
                    )
                    media_prompt_used_for_this_platform = original_prompt_for_platform
                    # actual_media_type_generated = requested_media_type
                else:
                    print(f"‚ö†Ô∏è Media generation failed or skipped for {platform_name}. No media asset will be linked.")
                media_path_idx += 1
            else:
                print(f"üîç Warning: Mismatch in media paths and platforms needing media for {platform_name}.")

        if upload_to_cloud:
            cloud_upload_task = upload_generated_post_files(
                filename_base=filename_base,
                platform=platform_name,
                text_content=text_content,  # Uses potentially translated text
                media_file_path=media_file_path,
                media_generation_prompt=media_prompt_used_for_this_platform
            )
            cloud_upload_tasks.append((platform_name, cloud_upload_task))

        final_posts_results.append(FinalGeneratedPost(
            platform=platform_name,
            post_type=platform_post_types_used[platform_name],
            text_file_path=text_file_path,
            media_asset=current_media_asset,
            original_text_content=text_content,  # This will store the final (potentially translated) text
            media_generation_prompt_used=media_prompt_used_for_this_platform
        ))

    # --- Execute Cloud Uploads Concurrently ---
    if upload_to_cloud and cloud_upload_tasks:
        print(f"\n‚òÅÔ∏è Starting {len(cloud_upload_tasks)} cloud upload tasks...")
        try:
            cloud_upload_results_tuples = await asyncio.gather(*(task for _, task in cloud_upload_tasks))
            for i, upload_result in enumerate(cloud_upload_results_tuples):
                platform_name_for_upload = cloud_upload_tasks[i][0]  # Renamed for clarity
                cloud_upload_results_list.append({
                    "platform": platform_name_for_upload,
                    "upload_result": upload_result
                })
                for post in final_posts_results:
                    if post["platform"] == platform_name_for_upload:
                        post["cloud_storage"] = upload_result  # type: ignore
                        break
        except Exception as e:
            print(f"üö® Error during cloud uploads: {e}")

    # --- Create and Upload Summary ---
    pipeline_summary = {
        "pipeline_id": f"{filename_base}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
        "subject": subject,
        "platform_configurations": platform_configs,
        "language_used": language,  # Reports the target language
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "posts": final_posts_results,
        "cloud_uploads_summary": cloud_upload_results_list,
        "requirements": requirements,
        "posts_history": posts_history
    }

    summary_filename = os.path.join(BASE_OUTPUT_FOLDER, f"{filename_base}_summary.json")
    try:
        with open(summary_filename, "w", encoding='utf-8') as f:
            json.dump(pipeline_summary, f, indent=4, ensure_ascii=False)
        print(f"üìã Local summary saved to {summary_filename}")
    except IOError as e:
        print(f"üö® Error saving local summary: {e}")

    if upload_to_cloud:
        try:
            summary_cloud_path = cloud_storage.generate_cloud_path(
                filename_base, "summary", "metadata", "json"
            )
            summary_upload_result = await cloud_storage.upload_json_data(
                pipeline_summary,
                summary_cloud_path,
                metadata={
                    "content_type": "pipeline_summary",
                    "subject": subject,
                    "platforms_configured_count": str(len(platform_configs)),
                    "language": language
                }
            )
            pipeline_summary["summary_cloud_storage"] = summary_upload_result  # type: ignore
            print(f"‚òÅÔ∏è Summary uploaded to cloud: {summary_upload_result.get('public_url', 'URL not available')}")
        except Exception as e:
            print(f"üö® Error uploading summary to cloud: {e}")

    print("\n‚úÖ Social Media Post Generation Pipeline Complete! ‚úÖ")
    return pipeline_summary


async def main():
    """Main function with enhanced cloud integration."""

    sample_posts_history: List[PostHistoryEntry] = [
        {"post_type": "A", "count": 7, "score": 8},
        {"post_type": "B", "count": 5, "score": 9},
        {"post_type": "C", "count": 3, "score": 7}
    ]

    # The orchestrator now uses PLATFORMS_POST_TYPES_MAP from config.py
    # So, target_platforms argument is removed from generate_social_media_posts_pipeline call
    pipeline_result = await generate_social_media_posts_pipeline(
        posts_history=sample_posts_history,
        upload_to_cloud=True
    )

    print("\n" + "=" * 60)
    print("DODOOOOOOOOOOOOOOOOOOOOOOOOOOOOO üìä PIPELINE EXECUTION SUMMARY")
    print("=" * 60)

    print(f"Pipeline ID: {pipeline_result['pipeline_id']}")
    print(f"Subject: {pipeline_result['subject']}")
    # print(f"Post Type: {pipeline_result['post_type']}") # Removed global post type
    print(f"Language: {pipeline_result.get('language_used', 'N/A')}")
    print(f"Platform Configurations: {json.dumps(pipeline_result.get('platform_configurations'))}")
    print(f"Generated At: {pipeline_result['generated_at']}")

    print(f"\nüì± GENERATED POSTS ({len(pipeline_result['posts'])} total):")
    for i, post_info in enumerate(pipeline_result['posts']):
        print(f"\n--- Post {i + 1}: {post_info['platform'].upper()} (Type: {post_info['post_type']}) ---")
        print(f"Text Preview: {post_info['original_text_content'][:100]}...")

        if post_info.get('media_asset'):
            media_asset = post_info['media_asset']
            print(f"Media: {media_asset['type']} - {media_asset['file_path']}")  # type: ignore
            if post_info.get('media_generation_prompt_used'):
                print(f"Media Prompt: {post_info['media_generation_prompt_used'][:70]}...")

        if post_info.get('cloud_storage'):
            cloud_info = post_info['cloud_storage']
            print(f"‚òÅÔ∏è Cloud Storage:")
            if isinstance(cloud_info, dict) and 'uploads' in cloud_info:  # Check structure
                for upload in cloud_info.get('uploads', []):
                    if isinstance(upload, dict) and upload.get('success'):  # Check structure
                        print(f"  ‚úÖ {upload.get('cloud_path', 'Unknown path')}")
                        print(f"     URL: {upload.get('public_url', 'URL not available')}")
                    elif isinstance(upload, dict):
                        print(f"  ‚ùå Upload failed: {upload.get('error', 'Unknown error')}")
                    else:
                        print(f"  ‚ùì Unknown cloud upload item format: {upload}")
            else:
                print(f"  ‚ùì Cloud storage info format unexpected: {cloud_info}")

    if pipeline_result.get('summary_cloud_storage'):
        summary_cloud = pipeline_result['summary_cloud_storage']
        if isinstance(summary_cloud, dict) and summary_cloud.get('success'):  # Check structure
            print(f"\nüìã Summary Cloud Storage:")
            print(f"  ‚úÖ {summary_cloud.get('public_url', 'URL not available')}")
        elif isinstance(summary_cloud, dict):
            print(f"  ‚ùå Summary upload failed: {summary_cloud.get('error', 'Unknown error')}")
        else:
            print(f"  ‚ùì Summary cloud storage info format unexpected: {summary_cloud}")

    print(f"\nüåê WEB APP INTEGRATION:")
    print(f"Your Vite/TSX web app can now retrieve all generated content from:")
    print(f"- Individual post files via their public URLs")
    print(f"- Complete pipeline summary via the summary JSON URL")
    print(f"- Use the pipeline_id '{pipeline_result['pipeline_id']}' to track this generation")

    print("\nüèÅ All operations completed!")


async def generate_enhanced_social_media_posts_pipeline(
    request_data: ContentGeneratorData
) -> Dict[str, Any]:
    """
    Enhanced pipeline that processes the new ContentGeneratorData structure with image controls.
    Supports hierarchical image control (Level 1 global, Level 2 platform-specific).
    """
    print("üöÄ Starting Enhanced Social Media Post Generation Pipeline üöÄ")
    
    # Extract data from the new structure
    company = request_data.company
    content = request_data.content
    image_control = request_data.image_control
    platforms = request_data.platforms
    
    # Filter selected platforms
    selected_platforms = [p for p in platforms if p.selected]
    if not selected_platforms:
        error_msg = "No platforms selected for content generation."
        print(f"üö´ Error: {error_msg}")
        return {
            "error": error_msg,
            "pipeline_id": f"{get_filename_base(content.topic)}_error_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            "subject": content.topic,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "posts": [],
            "cloud_uploads": []
        }
    
    # Convert to the format expected by the existing pipeline
    platforms_post_types_map = [
        {platform.platform: platform.post_type} for platform in selected_platforms
    ]
    
    # Create filename base from topic
    filename_base = get_filename_base(content.topic)
    print(f"üé¨ Using filename base: {filename_base}")
    
    # Prepare company colors for image enhancement
    company_colors = {
        "primary_color_1": company.primary_color_1,
        "primary_color_2": company.primary_color_2
    }
    
    # --- Layer 2: Core Text Generation (using existing structure) ---
    target_platforms = [p.platform for p in selected_platforms]
    layer2_input_data = Layer2Input(
        company_name=company.name,
        company_mission=company.mission,
        company_sentiment=company.tone_of_voice,  # Use tone_of_voice from company
        subject=content.topic,
        platforms_to_target=target_platforms,
        requirements=None,  # Could be derived from content.description if needed
        posts_history=None,  # Not provided in new structure
        language=request_data.language,
        tone=company.tone_of_voice,
        platform_post_type="Enhanced content with image controls"
    )
    
    layer2_result = await run_layer_2_decision_maker(layer2_input_data)
    core_post_text = layer2_result["core_post_text"]
    print(f"üìù Core post text generated: '{core_post_text[:100]}...'")
    
    # --- Enhanced Platform Adaptation with Image Controls ---
    platform_outputs_map = {}
    platforms_needing_media_info = []
    
    for platform in selected_platforms:
        platform_name = platform.platform
        print(f"‚öôÔ∏è Processing enhanced adaptation for {platform_name}")
        
        # Resolve effective image control for this platform
        effective_control = ImageControlProcessor.resolve_effective_image_control(
            image_control, platform_name
        )
        
        # Download starting image if provided
        starting_image_path = None
        if effective_control.starting_image_url:
            platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
            starting_image_path = await ImageControlProcessor.download_starting_image(
                effective_control.starting_image_url,
                platform_dir,
                filename_base
            )
            if starting_image_path:
                effective_control.starting_image_path = starting_image_path
        
        # Run platform adaptation
        platform_agent_input = PlatformAgentInput(
            company_name=company.name,
            company_mission=company.mission,
            company_sentiment=company.tone_of_voice,
            subject=content.topic,
            core_post_text_suggestion=core_post_text,
            platform_name=platform_name,
            platform_post_type=platform.post_type,
            language=request_data.language,
            tone=company.tone_of_voice
        )
        
        platform_result = await run_platform_adaptation_agent(platform_agent_input)
        
        # Enhance media prompt with image controls if media is needed
        original_media_prompt = platform_result.get("platform_media_generation_prompt")
        if original_media_prompt and effective_control.enabled:
            enhanced_prompt = ImageControlProcessor.enhance_prompt_with_image_controls(
                original_media_prompt,
                effective_control,
                company_colors
            )
            platform_result["platform_media_generation_prompt"] = enhanced_prompt
            print(f"üé® Enhanced media prompt for {platform_name}")
        
        platform_outputs_map[platform_name] = platform_result
        
        # Track platforms needing media
        if original_media_prompt:
            platforms_needing_media_info.append((
                platform_name,
                platform_result["platform_media_generation_prompt"],
                "image"  # Default to image for now
            ))
    
    # --- Enhanced Media Generation ---
    generated_media_paths = []
    if platforms_needing_media_info:
        print(f"\nüé® Generating {len(platforms_needing_media_info)} enhanced media assets...")
        
        media_generation_tasks = []
        for platform_name, enhanced_prompt, media_type in platforms_needing_media_info:
            platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
            
            # Get effective control for additional config
            effective_control = ImageControlProcessor.resolve_effective_image_control(
                image_control, platform_name
            )
            
            # Generate config for image generation
            image_config = ImageControlProcessor.get_image_generation_config(effective_control)
            
            task = generate_visual_asset_for_platform(
                image_prompt=enhanced_prompt,
                output_directory=platform_dir,
                filename_base=filename_base,
                media_type=media_type
            )
            media_generation_tasks.append(task)
        
        try:
            generated_media_paths = await asyncio.gather(*media_generation_tasks)
            print(f"‚úÖ Generated {len([p for p in generated_media_paths if p])} media assets successfully")
        except Exception as e:
            print(f"üö® Error during media generation: {e}")
            generated_media_paths = [None] * len(platforms_needing_media_info)
    
    # --- Assembly and Cloud Upload (similar to existing pipeline) ---
    final_posts_results = []
    cloud_upload_tasks = []
    cloud_upload_results_list = []
    
    media_path_idx = 0
    for platform in selected_platforms:
        platform_name = platform.platform
        platform_output_data = platform_outputs_map.get(platform_name)
        if not platform_output_data:
            continue
        
        platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
        text_content = platform_output_data["platform_specific_text"]
        
        # Add hashtags and CTA to text content
        enhanced_text = text_content
        if content.hashtags:
            enhanced_text += f"\n\n{' '.join(['#' + tag for tag in content.hashtags])}"
        if content.call_to_action:
            enhanced_text += f"\n\n{content.call_to_action}"
        
        text_file_path = save_text_content(platform_dir, filename_base, enhanced_text)
        
        # Handle media assets
        current_media_asset = None
        media_prompt_used = None
        media_file_path = None
        
        media_info = next((info for info in platforms_needing_media_info if info[0] == platform_name), None)
        if media_info and media_path_idx < len(generated_media_paths):
            path_or_none = generated_media_paths[media_path_idx]
            if path_or_none:
                media_file_path = path_or_none
                current_media_asset = SavedMediaAsset(
                    type="image",
                    file_path=media_file_path
                )
                media_prompt_used = media_info[1]
            media_path_idx += 1
        
        # Cloud upload
        if request_data.upload_to_cloud:
            cloud_upload_task = upload_generated_post_files(
                filename_base=filename_base,
                platform=platform_name,
                text_content=enhanced_text,
                media_file_path=media_file_path,
                media_generation_prompt=media_prompt_used
            )
            cloud_upload_tasks.append((platform_name, cloud_upload_task))
        
        final_posts_results.append(FinalGeneratedPost(
            platform=platform_name,
            post_type=platform.post_type,
            text_file_path=text_file_path,
            media_asset=current_media_asset,
            original_text_content=enhanced_text,
            media_generation_prompt_used=media_prompt_used
        ))
    
    # Execute cloud uploads
    if request_data.upload_to_cloud and cloud_upload_tasks:
        print(f"\n‚òÅÔ∏è Starting {len(cloud_upload_tasks)} cloud upload tasks...")
        try:
            cloud_upload_results_tuples = await asyncio.gather(*(task for _, task in cloud_upload_tasks))
            for i, upload_result in enumerate(cloud_upload_results_tuples):
                platform_name_for_upload = cloud_upload_tasks[i][0]
                cloud_upload_results_list.append({
                    "platform": platform_name_for_upload,
                    "upload_result": upload_result
                })
                for post in final_posts_results:
                    if post["platform"] == platform_name_for_upload:
                        post["cloud_storage"] = upload_result
                        break
        except Exception as e:
            print(f"üö® Error during cloud uploads: {e}")
    
    # Create summary
    pipeline_summary = {
        "pipeline_id": f"{filename_base}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
        "subject": content.topic,
        "company_info": {
            "name": company.name,
            "mission": company.mission,
            "tone_of_voice": company.tone_of_voice
        },
        "content_details": {
            "topic": content.topic,
            "description": content.description,
            "hashtags": content.hashtags,
            "call_to_action": content.call_to_action
        },
        "image_controls_used": {
            "level_1_enabled": image_control.level_1.enabled,
            "level_2_overrides": len([p for p in [
                image_control.level_2.facebook,
                image_control.level_2.instagram,
                image_control.level_2.linkedin,
                image_control.level_2.twitter
            ] if p and p.enabled])
        },
        "language_used": request_data.language,
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "posts": final_posts_results,
        "cloud_uploads_summary": cloud_upload_results_list
    }
    
    # Save and upload summary
    summary_filename = os.path.join(BASE_OUTPUT_FOLDER, f"{filename_base}_enhanced_summary.json")
    try:
        with open(summary_filename, "w", encoding='utf-8') as f:
            json.dump(pipeline_summary, f, indent=4, ensure_ascii=False)
        print(f"üìã Enhanced summary saved to {summary_filename}")
    except IOError as e:
        print(f"üö® Error saving enhanced summary: {e}")
    
    if request_data.upload_to_cloud:
        try:
            summary_cloud_path = cloud_storage.generate_cloud_path(
                filename_base, "enhanced_summary", "metadata", "json"
            )
            summary_upload_result = await cloud_storage.upload_json_data(
                pipeline_summary,
                summary_cloud_path,
                metadata={
                    "content_type": "enhanced_pipeline_summary",
                    "subject": content.topic,
                    "company": company.name,
                    "platforms_count": str(len(selected_platforms)),
                    "language": request_data.language
                }
            )
            pipeline_summary["summary_cloud_storage"] = summary_upload_result
            print(f"‚òÅÔ∏è Enhanced summary uploaded to cloud: {summary_upload_result.get('public_url', 'URL not available')}")
        except Exception as e:
            print(f"üö® Error uploading enhanced summary to cloud: {e}")
    
    print("\n‚úÖ Enhanced Social Media Post Generation Pipeline Complete! ‚úÖ")
    return pipeline_summary


if __name__ == "__main__":
    asyncio.run(main())

